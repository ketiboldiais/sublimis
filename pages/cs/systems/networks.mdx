<Metadata
	title={"Computer Networks"}
	description={"Notes on computer networks"}
	keywords={"Computer networks, packets"}
/>

# Computer Networks

1. [A Brief History](#a-brief-history)
2. [The Internet](#the-internet)
   1. [Network Layers](#network-layers)
   2. [Protocols](#protocols)
3. [Terminology](#terminology)
   1. [Network Edges](#network-edges)
   2. [Network Edge Protocols](#network-edge-protocols)
   3. [Access Networks & Physical Links](#access-networks--physical-links)
   4. [Local Area Networks (LAN)](#local-area-networks-lan)
4. [Signals & Bandwidths](#signals--bandwidths)
5. [Network Core](#network-core)
   1. [Circuit Switching](#circuit-switching)
      1. [Bandwidth Division](#bandwidth-division)
         1. [Frequency Division Multiplexing](#frequency-division-multiplexing)
      2. [Time Division Multiplexing](#time-division-multiplexing)
      3. [Hybrid Multiplexing](#hybrid-multiplexing)
   2. [Throughput & Latency](#throughput--latency)
   3. [Packet Switching](#packet-switching)

What's the difference between a communication and a network?

One answer: There's a distinction between _communications_ and _networks_.
We can think of _communications_ as the plumbing of all the connections
between computers. _Networks_ are what actually go through the plumbing.
Alternatively, under this answer, we can think of communications as akin to
the actual, physical roads in a road system. In that sense, communications
experts are like civil engineers; they answer questions like: What
materials should the roads be made of? Under what temperatures do the
materials expand and contract? How much weight can the materials support?
In computer networking, the civil engineer in this example is the
electrical engineer's analog. Examining the questions, we can surmise that
the electrical engineer's questions pertain primarily to hardware.

The network experts, in contrast, are like urban planners. They answer such
questions as: Should this particular road be a one- or two-way? How many
lanes should this particular road have? What should the speed limit for
this road be? Where should I place this traffic light? How long should the
red traffic light remain on? Here, the urban planner is an analog of the
network engineer, whose questions are primarily related to software.

Another answer: A communication is the transfer of information from a
system ${\texttt{A}}$ to a system ${\texttt{C}.}$ If the transfer must be
given to some intermediate system—e.g., system ${\texttt{B}}$—in order to
reach system ${\texttt{C},}$ then we have a _network_. Otherwise, it's just
a communication.

## A Brief History

Arguably, the key event that started everything off was the 1961
publication of Leonard Kleinrock's paper on packet switching. Before
Kleinrock's ideas, networks were circuit switched. If Susan called Boram,
Susan's call would be routed to a switchboard operator, who would respond
by asking "Good evening madame, whom shall I connect you to?" To which
Susan would respond, "Good evening. Please connect me to Boram Seymour."
The operator would then take a jack and plug it into a particular port,
creating a physical, wired connection between Susan and Boram. Once
connected, Susan and Boram can speak to one another, just as we would
today. When Boram says, "Oh by the way," the sound waves generated by her
voice box travel down the wired connection, reaching Susan's receiver.

Kleinrock looked at all of these processes and came up with a different
approach: Instead of having some operator manually plugging in these
cables, why don't we do this. Take the signal, chop it up into tiny,
discrete pieces (a process called _sampling_), assign those pieces numbers.
For example, for the word `hi`, `h` might map to ${104,}$ `i` to ${105.}$
Then, we'll represent ${104}$ with this particular voltage, and ${105}$
with this other voltage. A bundle of those voltages is called a **packet**,
and that's what will travel along the connections.

## The Internet

An internetwork is a set of millions of endpoints—you, me, Susan, Boram,
Susan's Apple watch and Boram's refrigerator—connected over a network. Some
of these endpoints are addressed by numbers, others behind a _virtual
endpoint._ Because an internetwork is itself a node, we can connect one
internetwork to another with a network. The network of all these
internetworks is **the Internet**.

<div id="network_components_1"></div>

Say we entered the TARDIS and jump back to the 1950s, emerging into the
sight of a tall, brooding figure—Eisenhower. Unsurprisingly astute,
Eisenhower capitalizes on the situation: Give me a complete architecture of
the Internet by Monday, 0900. Tall order. Where should we start?

A good starting point is to be clear about what the most important
objectives are. For the Internet, some of the most critical objectives
include:

- _Reliability._ We want to ensure that when packets are sent from point
  ${A}$ under the instruction to go to point ${B,}$ we want to ensure that
  they will in fact arrive at point ${B.}$

- _Speed._ We want the packets to get to go from ${A}$ to ${B}$ as fast as
  possible, without sacrificing the other objectives.

- _Security._ If a packet is sent from ${A}$ to only ${B,}$ the packet
  should arrive at ${B}$ and only ${B.}$

In the modern era, the attempt to satisfy these objectives resulted in a
somewhat hierarchical structure. At the Internet's core are **ISPs
(Internet Service Providers)**—entities that provide users access to larger
networks. An easy way to think about what exactly ISPs are is to consider
the following scenario.

Susan and Boram move in to a new house. The two have their own computers,
with lots of movies, music, and books. They don't have Internet yet, so
they start by establishing a network between their computers, allowing one
another to browse the other's media folders:

<div id="net1"></div>

After a few weeks, two more people—Jane and Sadik—build a house near Susan
and Boram's. Jane and Sadik also decide to share the movies, music, and
books they have, so they enlist Susan to make the network connections:

<div id="net2"></div>

Eventually, many more people join the neighborhood, all willing to share
their data. Susan works tirelessly away:

<div id="net3"></div>

Despite this increasingly complicated web of networks, the neighborhood
only holds a tiny, tiny fraction of all the possible media they can get
their hands on. After a few months, a company called Conekt—from a large
town nearby—calls Susan: Hey, we've seen all this work you've done for the
neighborhood. Would you want to connect to our network?

Susan is ecstatic, calls a neighborhood meeting, and puts the proposal to a
vote. Unanimous approval within minutes. So Conekt comes to Susan's
neighborhood—called `n1` (_neighborhood 1_)—and begins making the
connections:

<div id="net4"></div>

Why did the neighborhood jump on board so quickly? Because it turns out
that Conekt is an _ISP_—their network connects to numerous other networks.
And even more importantly, Conekt itself is connected to even larger ISPs:

<div id="net5"></div>

ISPs are organized by hierarchy. **Tier-1 ISPs** are the largest ISPs with
national and international coverage. These ISPs include companies like
AT&T, Sprint, CenturyLink, Deutsche Telekom, NTT Communications, and a few
others. Tier-1 ISPs are the entities that go out and hire companies to lay
down the cables connecting networks across the United States to Asia,
Europe, South America, and Africa. Who pays these Tier-1 ISPs? National
governments and _tier-2 ISPs_.

**Tier-2 ISPs** are also entities that provide access to networks,
ultimately connecting to a Tier-1 ISP. Tier-2 ISPs are smaller and more
often regional network providers. Think Comcast, Virgin Media, Cox
Communications, CTS Telecom, and so on. These entities provide internet
access for regions—southwest Michigan, central California, upstate New
York, and so on. When these entities are paid, part of the money goes to
Comcast as profit, and another part of it goes to a Tier-1 ISP (for
Comcast, Tata Communications, India's Tier-1 ISP). Who pays the Tier-2
ISPs? , state governments, large enterprises, and _Tier-3 ISPs_.

The Tier-3 ISPs are the ISPs we, as people, interact with directly. They're
_access providers_ and include entities like Time Warner Cable, Earthlink,
Boost Mobile, Virgin Mobile, Xfinity, Frontier, Suddenlink, and many, many
others. Who pays the Tier-3 ISPs? Well, us, and _local ISPs_. **Local
ISPs** are network providers for smaller areas. They aren't as large as
Tier-3 ISPs, but bigger than the average user. For example, iTV provides
access for small pockets of neighborhoods throughout Illinois. Local ISPs
also include the network access providers like major universities and
hospitals.

Putting all of this together, we can see why the Internet hasn't descended
into chaos. There's a rough hierarchy, maintained by supply and demand. We
pay the local ISP to transport our email from Madison, Wisconsin, to Tokyo,
Japan. The local ISP pays the tier-3 ISP to transport the email, perhaps to
Chicago. The tier-3 ISP pays the tier-2 ISP to transport the email to
somewhere in California. The tier-2 ISP pays the tier-1 ISP to send the
email to a tier-1 ISP in Asia. The tier-2 ISP in Tokyo pays the Asian
tier-1 ISP to receive that email, followed by a tier-3 ISP, a tier-2 ISP,
and finally a local Japanese ISP.

### Network Layers

While the Internet has a rough hierarchy, it's more Pollock-meets-Picasso
than M.C. Escher. There are outlines here and there, but much of it is a
smorgasbord of dizzying components: hosts, routers, applications, antennas,
satellites, cables, hardware, software, and so on. All of these components
have unique, dedicated tasks, so how do we ensure that one component
doesn't go off ruining things for everyone else?

One way to solve this problem is to shift the way we think about the
Internet. Instead of thinking of the Internet as some physical
connection—as we did in the previous section—we want to think of it as a
**service**. For example, we could think of air travel in terms of its
physical components. There are airplanes, airports, security gates,
travelers, flight attendants, pilots, airport restaurants, etc. And just
like the Internet, we have regional airlines, national airlines, and
international airlines. How does air travel not collapse because of all
these different components and self-interests? Through **layers of
services** and **protocols** (i.e., laws). We'll discuss the protocol
aspect later, but for now, let's focus on the layers of services.

Suppose our friend Allen buys a ticket from Jacksonville, North Carolina,
to LA, California. This is a fairly long flightpath. Allen goes to Albert
J. Ellis Airport (OAJ)—a small regional airport—and boards a Southwest
Airlines flight to LAX, a large international airport. To get to LA, Allen
has his baggage checked in at OAJ, then gets to the gates, and eventually
takes off. In essence, there are a layer of services, or points, from top
to bottom:

<div id="airline_service"></div>

When Allen gets to LAX, he goes through the same layers of services and
points, from bottom to top:

<div id="airline_service2"></div>

We see the same idea at work with the Internet. Suppose we're waiting at
O'Hare airport and we visit `CNN.com`. Entering the URL, we go through
several layers. First, the **application layer**, our browser. By entering
the URL into our address bar and hitting enter, we're telling the browser
to communicate with the CNN application, stored on some server in, say,
Atlanta. For this communication to occur, the application layer then
creates a packet, attaches a message to it, and sends it to the **transport
layer**, which also exists on our laptop:

<div id="packet1"></div>

<div id="internet_service_layers"></div>

The transport layer receives this packet, and recognizes that it must
deliver this packet to the _transport layer_ of the server in Atlanta. This
is akin to how a baggage tag from the Jacksonville airport's baggage
check-in area is only understood by the baggage handlers at the LAX baggage
claim area. To ensure the CNN server's transportation layer understands
what to do when it receives the transport layer's communication, the
transport layer provides what we can think of as a barcode—some kind of
information that allows the CNN server's transport layer to determine which
application layer the message it receives belongs to. This information also
ensures that the packet doesn't get lost, and in the event it does, not in
the wrong hands. So, it adds this additional information—called a
**segment**—to the packet:

<div id="packet2"></div>

The transport layer then sends this packet to the **network layer**. The
network layer's job is to determine the fastest possible route to Atlanta.
Should it go to St. Louis then Atlanta? Indianapolis? Washington D.C.? The
transport layer is only focused on efficiency; it doesn't worry about
security, or whether there's anything wrong with the message. It just
focuses on efficiency. Once the transport layer figures out the best
possible routes to take, it adds its determinations—called a
**datagram**—to the packet:

<div id="packet3"></div>

The transport layer then sends the packet to the **link layer**. The link
layer's job is to define the start (through information called the _frame
header_) and end of the packet (the _frame footer_), as well as information
that allows the next device's physical layer to interpret the packet:

<div id="packet4"></div>

Once the link layer is done, it sends the packet to the **physical
layer**—perhaps a physical cable (e.g., Ethernet or a phone line) or, in
the modern era, a radio signal (WiFi). Let's say it's a WiFi signal. The
physical layer—a WiFi card—receives the packet, looks at the link
information, and tells our laptop's WiFi antenna to vibrate at particular
frequencies (essentially, the physical form of the packet).

This radio waves (the packet) is received by a **switch**, a device that
routes packets elsewhere (in our case, a WiFi router). The WiFi router's
physical layer—another radio antenna—receives these radio waves, and using
the frame information, samples the signal into bits. These bits are then
sent to the WiFi router's _link layer_.

The WiFi router's link layer then looks at the datagram, and only the
datagram (remember, each layer only understands its corresponding layer
from the sending device). Part of the datagram contains our device's **MAC
(Media Access Control) address**, which we can think of as our device's
unique ID. Seeing our MAC address, the WiFi router is programmed to forward
the packet elsewhere. To ensure the packet is sent to the next router, the
WiFi router removes the previous frames, and adds new ones:

<div id="packet5"></div>

This is because the previous frames only included information providing
that the packet gets to the WiFi router. It's the same idea behind the
physical baggage tag numbers for multiple flights. If a bag is supposed to
go from JFK to ORD to LAX, the baggage handlers at JFK must include
information providing that the bag's headed to ORD. When it gets to ORD,
the baggage handlers there have to remove the information "To ORD",
replacing it instead, with, "To LAX."[^wifi_note]

[^wifi_note]:
    Importantly, the WiFi router only has a physical layer and a link
    layer. It does not have a network layer. As such, it cannot touch the
    network, transport, and application layers' provided information.

The WiFi router then sends this to a **router**, a larger device that
directs network traffic. That router might be located in St. Louis. The
packet goes to the router's physical layer, which samples the packet into
bits, and sends those bits to the link layer.

The link layer looks at these bits, and sees that it came from our WiFi
router. Recognizing this fact, the link layer removes the frames, and
passes it to the router's network layer. The network layer looks at the
datagram, and sees that's it's supposed to go to Atlanta. So, it removes
the old datagram and adds a new one: The new datagram provides that the
packet should go to Atlanta, but the next hub should be Washington D.C.

The network layer then hands the modified packet to the link layer. The
link layer then adds new frames, this time including the Washington D.C.
router's hardware address:

<div id="packet6"></div>

This process continues, going from router to router, until it finally
reaches the server in Atlanta. Once there, it passes through layers, just
as we've discussed at length. The packet gets to the server's physical
layer, which samples the signal into bits. The bits are sent to the link
layer, which then sees that the packet is supposed to go to the hardware
address of the CNN server in Atlanta. That's me!" Knowing this fact, the
link layer removes the frames, and sends the packet up to the network
layer.

The network layer looks at the datagram, and sees that the packet is
supposed to go to the CNN server in Atlanta. "That's me!" The network layer
removes the datagram, and sends it up to the transport layer.

The transport layer looks at the segment, which looks at the packet's
number. Suppose that number is `195`. The transport layer asks, "What was
previous packet's number?" It determines that it was `194` and concludes
that the packet was received in order. So, the transport layer sends the
packet up to the application layer.

The application layer—some backend framework, perhaps Node.js—looks at the
_message_, and sees that it's a `GET` request for `CNN.com`. So, the
application layer creates a new packet, and in that packet's message, it
places `CNN.com`'s `index.html` file, and sends that packet on its way. The
process continues.

### Protocols

The Internet is also held together by **protocols**—rules defining the
format of messages, the order they're sent and received among network
entities, and the actions those entities must take upon message
transmission and receipt.

Protocols ensure that we don't have situations where messages crash into
one another, entities talking to each other at the same time, or waiting
too long to respond or speak.

Designing these protocols is tricky. We have to balance both fairness and
efficiency. To illustrate, consider the problem of a Zoom meeting.
Undoubtedly, we've all witnessed the situation where attendees speak over
one another. How might we avoid this problem? Well, we could write a
protocol instructing attendees to be cautious: Have something to say? Wait
for ${5}$ seconds and if no one else has spoken, speak.

But does this actually solve the problem? Not really. Some of us have also
seen situations where the Zoom speaker asks, "Any questions?" ${5}$ seconds
pass and suddenly there are two attendees asking questions at the same
time. A few "No please go ahead" are exchanged. ${2}$ seconds pass and
again the two attendees speak over one another. Of course, the probability
of a collision is lowered with the protocol, but the problem nevertheless
remains.

How about this: Attendees each have a designated ${5}$ minutes to interrupt
and ask questions. Outside of those ${5}$ minutes, the attendee may not
speak. This is called a **fixed scheduling** approach, and it certainly
avoids collisions. But what's the problem? Efficiency. Given five
attendees, we could have a situation where the first four attendees have
nothing to ask but the fifth attendee has plenty to ask. In which case the
fifth attendee must not only wait for ${20}$ minutes, but could have used
some of the unused ${20}$ minutes. This is both inefficient and unfair.

The same kind of problem exists in networks. When we examine protocols in
closer detail later, we'll find that we want to maximize the amount of
time, but also need to be fair.

## Terminology

Still continuing in our broad overview, let's define a few pieces of
terminology to help us better understand ideas in later sections.

### Network Edges

**Network edges** are _internet leaves_. These are the _applications_
(e.g., browsers, the Facebook app, Instagram, mail clients) and _hosts_
(also called _end systems_) (web servers, file storage systems, etc).

Network edges are structured in one of two approaches: the **client-server
model** or the **peer-to-peer model**. In the client-server model, the
client host (e.g., a web browser) sends requests to a server that's always
on and listening to requests, and the server responds.

In the peer-to-peer model, there is no dedicated server, but every
machine—laptop, desktop, phone, smart watch, smart refrigerator, smart
${x}$—behaves as both a client and a server. This is the architecture
behind Skype, Blockchain, BitTorrent, and many others. If ${x}$ and ${y}$
are devices—called _peers_—in a peer-to-peer network, as long as both ${x}$
and ${y}$ are on and protocols are satisfied, ${x}$ and ${y}$ can connect
and exchange data.[^seeding_note]

[^seeding_note]:
    This is where the _seeding_ comes from in torrent services. When we
    torrent a file, we are downloading data from some other peer on the
    network. But, for us to download that data, the device containing that
    data must be "turned on" in the network. The device is turned on when
    its owner allows the torrent client to _seed_ the file. In the
    torrenting community, network peers that torrent files but do not seed
    are called _leechers_.

### Network Edge Protocols

With network edges, the primary goal is to transfer data between end
systems. To help achieve that goal, we use protocols. For example, one
protocol is the **Transmission Control Protocol (TCP)**. This is a protocol
aimed at achieving three objectives:

**Reliability.** TCP-compliant devices guarantee that packets are
transferred as a stream of bytes, called a _byte stream_. They further that
the packets are transferred in order. That is, packet ${4}$ will never come
before packet ${3,}$ and packet ${3}$ will always come after packet ${2.}$
This ensures that we don't see Sammy Sosa running all the bases and then
cut to him hitting the homerun, or Gordon Ramsay scrambling eggs followed
by him cracking the eggs.

Importantly, reliability doesn't mean we will always get the data. We've
all seen the live Super Bowl stream where we suddenly cut to a touchdown.
TCP's reliability objective is that it will always notify clients when it
fails. If data is lost, or if an objective is not met, TCP will acknowledge
its failure and retransmit.

**Flow control.** TCP-compliant _senders_ guarantee that they will inform
TCP-compliant _receivers_ how much data they will send. This gives
receivers notice, allowing them to prepare, decline, or inform the senders
that they can no longer receive data. In turn, this prevents receivers from
being overwhelmed.

**Congestion control.** Given two TCP-complaint end-hosts—e.g., our phone
and the YouTube server—if routers between the two end-hosts become
congested, then the server will slow down the rate at which it transmits
packets.

This congestion control ensures routers—the intermediaries between the
YouTube server and our phone—aren't overwhelmed. Routers are devices too,
and they have a finite amount of memory. If they run out of that memory,
all of the packets comprising that Vine compilation we were watching are
lost, and the stops.

There are many other protocols used in network edges:

<div id="protocol_tree"></div>

We will examine these protocols in later sections, but here are a few brief
descriptions for some of these protocols:

1. **User Datagram Protocol (UDP)** is non-TCP protocol. It's a
   connectionless, unreliable data transfer protocol. Unlike TCP, there are
   no flow control or congestion control guarantees. UDP, however, leads to
   extremely fast connections. UDP is used for media streaming,
   teleconferencing, DNS, and Internet telephony. UDP is an ideal protocol
   for packet transfers where it would do more harm than good to retransfer
   information, as TCP does. For example, a common UDP protocol is **Domain
   Name Server (DNS)**. When we visit `bing.com`, our browser sends a
   request to a domain name server. That server is essentially an address
   book that matches names like `bing.com` to a specific numeric address
   called an _IP address_, which is the address of the server hosting
   `bing.com`. We can see this IP address by running the command
   `ping ⟨www.website_address.extension⟩`. At the time of this writing,
   it's `204.79.197.200`. This is a request for a very small amount of
   data, so it makes more sense to use a UDP protocol, namely, DNS.

2. **Hypertext Transfer Protocol (HTTP)** is an application layer TCP
   protocol for establishing connections between different websites. It's
   what clients use to request data, and what servers use to respond with
   data. HTTP is fastest when the data transfers consist of many small
   files. This is the protocol used by the most of the websites we visit.
   When we go to `espn.com` on our laptop, our browser sends an HTTP
   request to the `espn.com` server, which then sends an HTTP response
   containing the data comprising the `espn.com` page that's supposed to be
   returned.

3. **File Transfer Protocol (FTP)** is another application layer TCP
   protocol, used for file transfers. It's faster for single, large file
   transfers. Applications that use FTP include FileZilla, Transmit,
   WinSCP, and WS_FTP—all applications used for uploading, downloading, and
   managing files on a server.

4. **Telnet** is a TCP protocol for remote logins.

5. **Simple Main Transfer Protocol (SMTP)** is a TCP protocol for sending
   and receiving email.

**Voice over Internet Protocol (VoIP)** is a UDP protocol for making voice
calls over an Internet connection instead of a regular (analog) phone line.
Applications that use VoIP include Skype, Whatsapp, and Google Voice.

### Access Networks & Physical Links

As we know, routers are the large devices that connect large parts of the
Internet to other large parts. For example, networks in Japan to networks
in the United States. These routers are connected with large, thick,
fiber-optic cables.

Connected to these routers are smaller, regional networks. These
connections are established through smaller, thinner cables, usually either
fiber optic or copper.

Connected to these smaller, regional networks are _end
networks_—residential access networks (e.g., the networks provided by
smaller ISPs like iTV and Xfinity), institutional access networks (networks
at school or a company), and mobile access networks (networks provided by
cell towers). These networks are connected to the smaller regional networks
either by cable or wirelessly.

Finally, connected to these end networks are our laptops, phones, tables,
servers, and so on. These networks are connected to the smaller networks
wirelessly (e.g., using LTE on our phone when we're travelling or our
house's WiFi network) or by cable (e.g., an ethernet cable at work or a
phone line).

All of these connections are **links**, and they have a **bandwidth**—how
many bits are transferred per second. More specficially, a link's bandwidth
is the amount of frequency we have available for transferring packets. If a
link has ${1~000~000 \textsf{Hz}}$ of frequency, it has ${1 \textsf{MHz}}$
of bandwidth. The larger this bandwidth, the higher the rate at which we
can transfer bits, called the **bit rate**, measured in bits per second.
This is given by _shannon's bit rate formula_:

$$
 \textsf{bit rate} = \textsf{bandwidth} \times \lg \left(1 + \dfrac{\textsf{P}_R}{\textsf{N}_R}\right)
$$

where ${\textsf{P}_R}$ is the power received by the receiver, and
${\textsf{N}_R}$ is the noise received by the receiver. The links between
routers—fiber optic cables—have an extremely large bandwidth. This is why
they have bit rates of hundreds of gigabytes per second.

As we get closer to the edge networks, the bandwidths get smaller. Links in
these networks are simply physically smaller or are
wireless.[^wireless_link_note] In the days of dial-up, physical links at
the residential access level were shared with the phone line. This led to
top speeds of ${56 \textsf{bps}}$ (far, far slower compared to today's
speeds). It also meant we couldn't use the phone and surf the Internet at
the same time.

[^wireless_link_note]:
    As an aside, a wireless link can never be faster than the fastest wired
    link. This is a direct result of _shannon's bit rate formula_. The term
    that ultimately determines a bit rate is the power received by the
    receiver. This is because the bandwidth term is independent of whether
    a link if wired or wireless (if the only available frequencies were
    ${2.1 \textsf{Hz}}$ to ${2.9 \textsf{Hz}}$ and we used all of them,
    we'd have the police knocking on our door informing us our connections
    were causing interferences).

    Because the power received by the receive is what ultimately impacts
    bit rate, wireless links can never be faster than the fastest wired
    link. Wireless transmitters send power in all directions radially, so
    only a fraction of the transmitted power is received by a receiver.
    Contrast this with a wired link, where _all_ of the transmitted power
    is directed at the receiver.

Eventually, the asymmetric digital subscriber line (ADSL)[^dsl_note]
replaced dial-up, and users started seeing upload bit rates of
${1 \textsf{Mbps}}$ and download bit rates ${8 \textsf{Mbps}.}$ Why was
uploading slower than downloading? Because of the way the ISPs divided the
bandwidth: A small fraction of the bandwidth for upstreams, and most of the
bandwidth for downstreams. Why this division? Because this was before the
era of cloud-based services and social media—users downloaded data more
than they uploaded.

[^dsl_note]: Or _DSL_ for short.

After ADSL came **cable modems**, the prevailing standard today. These
wires were a mixture of cable and fiber, connecting homes directly to a
local ISP's router through a shared bus. Cable modems had much bigger
bandwidths, allowing downstream bit rates of up ${30 \textsf{Mbps}}$ and
upload bit rates of ${2 \textsf{Mbps}.}$ The cost, however, was that
residents had to share the connections. If everyone used the connection at
the same time, everyone would get a fraction of the available bandwidth.

The ISP companies, however, were quick to rebut the concerns, arguing that
the probability of everyone using the connection at the same time were
negligible. Pre-pandemic, this may have been true (although, there are
clearly peak traffic times; e.g., people getting home at ${6}$ and
streaming Netflix while they eat dinner). But it certainly wouldn't have
been the case during Covid times.

Nevertheless, plenty of people bought the argument, and the ISPs eventually
generated enough income to increase their cable bandwidths, to the point
where they are now the standard for physical links at the residential
access level.[^isp_note]

[^isp_note]:
    Of note, some ISPs today engage in suspicious marketing endeavors,
    advertising "point-to-point" connections, where the connection bus
    splits in different directions, with each resident having their own
    access point. As much as the ISPs advertise these connections as
    "personal" or "private," they're still shared connections.

### Local Area Networks (LAN)

A **local area network (LAN)** is a group of computers or other devies that
share a wired or wireless link to a nearby edge router. For example, an
apartment might provide free WiFi, in which case all of the apartment's
residents share the link. Other examples include the computers in a
hospital, a university lab, or corporate office. A LAN could have as few as
two or three devices (e.g., a resident's WiFi network), or as many as
several thousands (a large corporate office).

A common technology associated with LAN is ethernet. For example, some
hotels provide an ethernet cable for guests to use. That cable ultimately
leads to some router in the hotel, which then leads to an edge router
elsewhere. Ethernet connections today support bitrates ranging from
${10 \textsf{Mbps}}$ to ${1 \textsf{Gbps}.}$

Wireless LANs are what we're likely most familar with. Wireless LANs are
informally called _WiFi networks_, and more formally called _802.11b/g
networks_. When WiFi was first released to the public (1999), users saw
bitrates of about ${2 \textsf{Mbps}.}$ Today, we get anywhere from ${100}$
to ${200 \textsf{Mbps}.}$

## Signals & Bandwidths

Suppose some device broadcasts a signal to some receiver. That signal
consists of potentially thousands of different frequences. The greatest
frequency within that broadcast, denoted ${f_{max},}$ is called the
signal's **bandwidth**.

Every communication uses some amount of bandwidth. WiFi, for example, has a
bandwidth of roughly 20MHz (in the graph below, the rectangle colored red).
On the other hand, some GPS device might broadcast at a bandwidth of 1MHz
(the rectangle colored yellow). A police radio might operate at a bandwidth
of 3MHz (the rectangle colored purple).

<Plot
	geo={[
		{
			type: "rectangle",
			xy: [0, 2.5],
			w: 20,
			h: 5,
			name: "wifi",
			stroke: "firebrick",
			fill: "red",
		},
		{
			type: "rectangle",
			xy: [0, 1.5],
			w: 5,
			h: 3,
			name: "radio",
			stroke: "teal",
			fill: "teal",
		},
		{
			type: "rectangle",
			xy: [0, 5],
			w: 2,
			h: 10,
			name: "gps",
			stroke: "goldenrod",
			fill: "yellow",
		},
		{ type: "label", id: "\\text{wifi}", xy: [10.5, 5] },
		{ type: "label", id: "\\text{gps}", xy: [1.2, 10.1] },
		{ type: "label", id: "\\text{police radio}", xy: [3, 3] },
	]}
	xLabel={"frequency"}
	yLabel={"samples"}
	xLabelWidth={80}
	yLabelWidth={40}
	domain={[-20, 20]}
	range={[-20, 20]}
	tickCount={10}
	id={"collisions1"}
/>

Examining the graph above, we can see overlaps in the frequencies. This
presents a problem. If we turned on a receiver to catch the signals, we'd
get all of them. Moreover, the frequencies we'd get would likely be
gobbledygook — the frequencies collide and interfere with one another.

So how do we prevent these devices' frequences from colliding? Well, if we
look at the graph above, all the rectangles are centered at ${(0,0).}$ For
each device, this point is called the **center frequency**. We can avoid
the overlaps by changing this center frequency:

<Plot
	geo={[
		{
			type: "rectangle",
			xy: [30, 2.5],
			w: 20,
			h: 5,
			stroke: "firebrick",
			fill: "red",
		},
		{
			type: "rectangle",
			xy: [4, 1.5],
			w: 5,
			h: 3,
			stroke: "teal",
			fill: "teal",
		},
		{
			type: "rectangle",
			xy: [10, 5],
			w: 2,
			h: 10,
			stroke: "goldenrod",
			fill: "yellow",
		},
		{ type: "label", id: "\\text{wifi}", xy: [40.5, 5] },
		{ type: "label", id: "\\text{gps}", xy: [10, 15] },
		{ type: "label", id: "\\text{police radio}", xy: [-10.5, 7] },
	]}
	xLabel={"frequency"}
	yLabel={"samples"}
	xLabelWidth={80}
	yLabelWidth={40}
	domain={[-50, 50]}
	range={[-50, 50]}
	tickCount={10}
	id={"collisions2"}
/>

How do device manufacturers know where to shift their central frequency?
They pick a central frequency, and pay millions of dollars to the federal
government to hold on to that frequency. Once they've paid for that
frequency, the government prevents all others from using that frequency
through the judicial system. In the United States, the Federal
Communications Commission (FCC) maintains a list of all the purchased
frequency spectrums, and device manufacturers must respect that list if
they want their products to stay on the market.[^fcc_note]

[^fcc_note]:
    Radio spectrum allocations can be found on the
    [FCC website](https://www.fcc.gov/engineering-technology/policy-and-rules-division/general/radio-spectrum-allocation).
    Frequency spectrums are an extremely valuable commodity, and market
    players — telecommunications and broadcasting companies like Comcast,
    Verizon Wireless, Dish Network and Walt Disney — fight tooth and nail
    to get a hold of the spectrums. Mobile phone providers like AT&T and
    Sprint are especially ferocious in this area, given that demand for
    mobile data has, and continues to grow, exponentially. _See_ Arash
    Maskooki, Gabriele Sabatino, & Nathalie Mitton, _Analysis & Performance
    Evaluation of the Next Generation Wireless Networks_, ~Modeling &
    Simulation of Computer Networks & Systems~ 601 (2015).

The trouble is, by shifting these frequences, we now have an issue on the
receiver's end. When we open our laptop and connect to a WiFi access point,
the laptop's WiFi antenna receives the WiFi signals at the center
frequency. Let's say that center frequency is 2.4GHz. At that center
frequency, our laptop can't process that signal in its raw form.

However, the signal the antenna receives has a particular shape or outline
— the shape of the data the transmitter is attempting to send. That shape
is a signal itself, and it propogates at 20MHz — WiFi's broadband. Our
laptop's antenna can receive this signal, and once it receives this signal,
it shifts the signal back to the unshifted center frequency. In our graph
above, this point was ${(0,0).}$ This process is called bringing the signal
back to **baseband**.

By bringing the signal back to baseband, the original signal at 2.4GHz (the
**carrier signal**) is stripped away, leaving just its outline. That
outline is what our computer can work with, and it begins decoding that
signal into the data our system needs.

Question: Is there any advantage to placing a central frequency at a higher
frequency? The intuitive answer is yes. The closer we are to 0, the more
congested the purchased frequencies are. At higher frequencies, however,
things start looking more sparse:

<Plot
	geo={[
		{
			type: "rectangle",
			xy: [13, 2.5],
			w: 2,
			h: 5,
			stroke: "firebrick",
			fill: "red",
		},
		{
			type: "rectangle",
			xy: [4, 1.5],
			w: 5,
			h: 3,
			stroke: "teal",
			fill: "teal",
		},
		{
			type: "rectangle",
			xy: [10, 5],
			w: 2,
			h: 10,
			stroke: "goldenrod",
			fill: "yellow",
		},
		{
			type: "rectangle",
			xy: [30, 5],
			w: 4,
			h: 10,
			stroke: "purple",
			fill: "purple",
		},
		{
			type: "rectangle",
			xy: [43, 4],
			w: 2,
			h: 8,
			stroke: "grey",
			fill: "grey",
		},
	]}
	xLabel={"frequency"}
	yLabel={"samples"}
	xLabelWidth={80}
	yLabelWidth={40}
	domain={[-50, 50]}
	range={[-50, 50]}
	tickCount={10}
	id={"sparse"}
/>

And with so much more available frequencies, we could potentially some
device using massive bandwidths, which in turn means faster download and
upload speeds. Indeed, this is what technologies like 5G advertise — their
central frequencies live at higher frequences, allowing them to provide
bandwidths to the tune of not MHz, but GHz.

Sadly, as with most things in life, there's no free lunch. The greater a
signal's central frequency, the shorter the signal's range. And the shorter
the signal's range, the more towers we need to receive and emit the signal.
Put simply, technologies with higher central frequencies like 5G are great
for small, densely populated areas. Scaling these technologies to reach
millions of devices across hundreds of thousands of square miles is a
different story. Providers would have to install potentially thousands of
towers to achieve the same range as technologies with smaller central
frequencies.

## Network Core

The **network core** is a network of routers and networks of networks. How
is data transferred through the network? There are two approaches:

1. **circuit switching**, and
2. **packet switching**

### Circuit Switching

Under the circuit switching approach, there's a physical connection — a
metal wire — connecting the source to the target. Memory is not required
under the circuit switching approach. The data flows like a constant stream
from one body to another, uninterrupted.

For example, in the network diagram below, there's a path (colored red)
from `device8` to `server1`.

<Graph
	data={[
		{
			link: [
				{ id: "server1", r: 10, radial: 25, focus: "blue" },
				{ id: "router1", radial: 15, focus: "green" },
			],
			focus: "hl",
		},
		{
			link: ["router1", { id: "router2", radial: 15, focus: "green" }],
			focus: "hl",
		},
		{ link: [{ id: "router3", radial: 15, focus: "green" }, "router1"] },
		{ link: ["device1", "router2"] },
		{ link: ["device2", "router3"] },
		{ link: ["device5", "router3"] },
		{ link: ["device6", "router3"] },
		{ link: ["device3", "router2"] },
		{ link: ["device4", "router2"] },
		{ link: ["device8", { id: "router4", radial: 15, focus: "green" }] },
		{ link: ["router4", "server1"] },
		{ link: ["device10", "router4"] },
		{ link: ["device11", "router4"] },
		{ link: ["device12", "router4"] },
		{ link: ["device8", "router2"], focus: "hl" },
	]}
	collisionRadius={40}
	edgeLength={60}
/>

Because of this uninterrupted flow, data is sent as is. No modification, no
chopping; it's sent as a whole. For circuit switching to work, the source
and the target must coordinate with one another in setting aside resources
for their **end-to-end call**.

Notice that in the diagram above, the path from `device8` to `server1` is
not the shortest path. The shortest path would be
`(device8, router4, server1)`. Why was the longer path taken? Likely
because `router4` cannot handle `device8` connecting to it. Perhaps its
reached its threshhold for the maximum number of connections, or perhaps
`device8` is not authorized to connect to it.

For all circuit switching technologies, endpoints on the network must
peform a call setup. Contacting the various nodes along the network for
permission to pass through them to the final source is part of this set up.
The clearest example of a technology employing the circuit switching
approach is the telephone network.

There are several benefits to circuit switches. First, performance is
guaranteed because of the physical connections. Having this kind of
guarantee leads to much more efficient resource allocation. Nodes along the
network can communicate with one another about their current statuses,
which in turn allows requesting sources to promptly request another node.

It also allows clients to use time more carefully. If a client knows that
it must send the data within ${x}$ seconds, it rely on its logic's timing
assumptions, because of the guarantee provided circuit switching.

These benefits, of course, come with a tradeoff. Circuit switches must take
the time to set up the call. That set up time can be significant.
Additionally, once a path has been allocated for a particular call, no
other network participants can use that path, even if the path is _idle_.
This can be inefficient.

#### Bandwidth Division

As mentioned earlier, technologies that use bandwidth division must
allocate network resources among its callers. Because circuit switches use
a physical connection, the most important resource is bandwidth. For most
circuit switches, bandwidth is allocated by dividing the bandwidth into
equal portions.

There are two ways to perform this division: (1) **frequency division
multiplexing**, (2) **time division multiplexing**, and (3) **hybrid
multiplexing**.

##### Frequency Division Multiplexing

With frequency division, bandwidth is divided horizontally (i.e., in terms
of frequency):

<Plot
	geo={[
		{
			type: "rectangle",
			xy: [20, 2],
			w: 40,
			h: 4,
			stroke: "firebrick",
			fill: "red",
		},
		{
			type: "rectangle",
			xy: [20, 6],
			w: 40,
			h: 4,
			stroke: "goldenrod",
		},
		{
			type: "rectangle",
			xy: [20, 10],
			w: 40,
			h: 4,
			stroke: "green",
		},
		{
			type: "rectangle",
			xy: [20, 14],
			w: 40,
			h: 4,
			stroke: "teal",
		},
		{ type: "label", xy: [42, 4], id: "\\text{John}" },
		{ type: "label", xy: [42, 8], id: "\\text{Louis}" },
		{ type: "label", xy: [42, 12], id: "\\text{Kyle}" },
		{ type: "label", xy: [42, 16], id: "\\text{Hikari}" },
	]}
	xLabel={{ text: "time", w: 20 }}
	yLabel={{ text: "frequency", w: 40 }}
	domain={[-50, 50]}
	range={[-50, 50]}
	tickCount={10}
	id={"fdm"}
/>

Each of the rectangles is a chunk of bandwidth allocated to the network's
users. For example, in the diagram above, John gets a certain amount of
bandwidth, Louis gets a certain amount of bandwidth, Kyle, Hikari, and so
on.

The advantage to frequency division multiplexing: Users have constant
access to the network. They can use the network whenever they'd like. This
is ideal for applications that require constant data transfer. For example,
simple online games and internet telephony (e.g., WhatsApp voice calls).
Internet telephony in particular is well-suited for frequency division
multiplexing. Voice signals operate at the KHz range — not even MHz. This
is a tiny amount of bandwidth.

The tradeoff: Users aren't getting the fastest possible network speeds.
Worse, the more users there are on the network, the more divisions must be
made. With more divisions, each user has a narrower band — slower network
speeds.

#### Time Division Multiplexing

With time division multiplexing, bandwidth is divided vertically (i.e., in
terms of time):

<Plot
	geo={[
		{
			type: "rectangle",
			xy: [2, 15],
			w: 4,
			h: 30,
			stroke: "firebrick",
		},
		{
			type: "rectangle",
			xy: [6, 15],
			w: 4,
			h: 30,
			stroke: "goldenrod",
		},
		{
			type: "rectangle",
			xy: [10, 15],
			w: 4,
			h: 30,
			stroke: "green",
		},
		{
			type: "rectangle",
			xy: [14, 15],
			w: 4,
			h: 30,
			stroke: "teal",
		},
	]}
	xLabel={{ text: "time", w: 20 }}
	yLabel={{ text: "frequency", w: 40 }}
	domain={[-50, 50]}
	range={[-50, 50]}
	tickCount={10}
	id={"tdm"}
/>

With time division multiplexing, the network's users have specified time
slots for when they may use the network. For example, Bill might have the
network from 9:00AM to 10:00AM, and Nikki might have the network from
2:00PM to 3:00PM, alongside other users before and after them.

The advantage to time division multiplexing: During the user's allocated
time band, they have the entire bandwidth to themselves. And if they have
the entire bandwidth to themselves, they have much faster upload and
download speeds.

The first tradeoff: Users do not have constant access to the network. They
can only use the network at specified times. This is a significant cost to
users that need data on demand.

The second tradeoff: The more users there are, the narrower the bands will
be — users have smaller time slots. This can be a problem for users that
must download large files. For example, an operating system. If the user
cannot fit the download in their time slot, they'll have to wait until
their next available slot. The operating system might have downloaded
completely under frequency division multiplexing in that time spent
waiting.

#### Hybrid Multiplexing

The third approach is a mixture of frequency division multiplexing and time
division multiplexing. In other words, we divide bandwidth in terms of both
time _and_ frequency:

<Plot
	geo={[
		{
			type: "rectangle",
			xy: [5, 5],
			w: 10,
			h: 10,
			stroke: "firebrick",
		},
		{
			type: "rectangle",
			xy: [5, 15],
			w: 10,
			h: 10,
			stroke: "goldenrod",
		},
		{
			type: "rectangle",
			xy: [15, 5],
			w: 10,
			h: 10,
			stroke: "green",
		},
		{
			type: "rectangle",
			xy: [15, 15],
			w: 10,
			h: 10,
			stroke: "teal",
		},
	]}
	xLabel={{ text: "time", w: 20 }}
	yLabel={{ text: "frequency", w: 40 }}
	domain={[-50, 50]}
	range={[-50, 50]}
	tickCount={10}
	id={"hdm"}
/>

This hybrid approach is what 4G uses.

### Throughput & Latency

The measure of **throughput** is packets (or bits) per unit of time.
**Latency** is the amount of time it takes to deliver a packet of bits.
Let's talk about throughput first.

Suppose we have some time frame ${x}$ (e.g., from 2:00PM to 2:01PM).
Throughput answers the question: How many packets are delivered in the time
frame ${x}$? The idea behind throughput is best explained by considering
the following:

<Plot
	geo={[
		{
			type: "point",
			xy: [0, 0],
			fill: "red",
		},
		{
			type: "point",
			xy: [5, 0],
			fill: "red",
		},
		{
			type: "point",
			xy: [10, 0],
			fill: "red",
		},
		{
			type: "point",
			xy: [15, 0],
			fill: "red",
		},
		{
			type: "point",
			xy: [20, 0],
			fill: "red",
		},
		{
			type: "point",
			xy: [25, 0],
			fill: "red",
		},
		{
			type: "point",
			xy: [9, 5],
			fill: "red",
		},
		{
			type: "point",
			xy: [10, 5],
			fill: "red",
		},
		{
			type: "point",
			xy: [11, 5],
			fill: "red",
		},
		{
			type: "point",
			xy: [24, 5],
			fill: "red",
		},
		{
			type: "point",
			xy: [25, 5],
			fill: "red",
		},
		{
			type: "point",
			xy: [26, 5],
			fill: "red",
		},
	]}
	xLabel={{ text: "time", w: 20 }}
	yLabel={{ text: "device", w: 20 }}
	xLabelWidth={80}
	yLabelWidth={40}
	domain={[-30, 30]}
	range={[-30, 30]}
	tickCount={10}
	id={"throughput"}
/>

In the graph above, device 0 delivers one packet every 5 units of time.
Device 5, however, delivers three packets every 10 units of time. Which of
these devices has better throughput? They have the same throughput. There
are six packets total, over 30 units of time. Thus, for both device 0 and
device 5, we have:

$$
  \dfrac{6}{30} = \dfrac{1}{5}
$$

Throughput and latency are distinct. To illustrate, consider a device that
sends some packet ${P_i.}$ Packet ${P_i}$ is placed in a queue and starts a
timer, and is then sent off once its dequeued. When ${p_i}$ enters the
receiver's queue, it stops its timer. The receiver then looks at all the
timer values from all the packets and averages them. This computed average
is the latency.

The graph below visualizes packets traveling from a source (the red line)
to a destination (the blue line). The green lines indicate the packets'
paths.

<Plot
	geo={[
		{ type: "line", start: [1, 10], end: [1, -10], class: "red" },
		{ type: "line", start: [6, 10], end: [6, -10], class: "blue" },
		{ type: "segment", start: [1, 10], end: [6, 8], class: "green" },
		{ type: "segment", start: [1, 8], end: [6, 6], class: "green" },
		{ type: "segment", start: [1, 6], end: [6, 4], class: "green" },
		{ type: "line", start: [-6, 10], end: [-6, -10], class: "red" },
		{ type: "line", start: [-1, 10], end: [-1, -10], class: "blue" },
		{ type: "segment", start: [-6, 8], end: [-1, 6], class: "green" },
		{ type: "segment", start: [-6, 7.8], end: [-1, 5.8], class: "green" },
		{ type: "segment", start: [-6, 8.2], end: [-1, 6.2], class: "green" },
	]}
	id="throughput_compare"
	yLabel={{ text: "time", w: 20 }}
	renderXAxis={false}
	yLabelWidth={30}
	noTicks={true}
/>

Comparing these two visualizations, the scenario to the left (device 5 in
the previous example), has a much higher average than the scenario to the
right (device 0 in the previous example). This demonstrates the distinction
between latency and throughput — devices can have the same throughput but
different latencies, and vice versa.

### Packet Switching

Under the packet switching approach, for data to travel from ${A}$ to
${B,}$ it must first be chopped up into discrete chunks of data. These
chunks are then sent towards point ${B,}$ stopping at various intermediary
points. At each of those points, the chunk is stored in memory, and must
wait for further instructions on where to go next.

In circuit switching, we saw that recourses are divided at the router
level. Packet switching eschews this approach. Instead of dividing the
resources, a queue is created at the router.

Suppose there are two devices ${A}$ and ${B}$ attempting to send packets to
some router ${R.}$ For these packets to arrive at their destination ${A}$
and ${B}$ must deliver their packets to the packet queue contained in
${R.}$ Once inside the queue, the router dequeues the queue, and sends the
dequeued packet on its way to the next node.

The advantage to this approach: If ${A}$ doesn't have very many packets to
send, ${B}$ can continue sending packets to ${R}$'s queue, without having
to wait for ${A.}$ Because packets are sent with a queue (a
first-in-first-out data structure), ${B}$'s packets are sent without issue.

This approach is called **statistical multiplexing**. Thus, unlike circuit
switching, network resources are _shared_ between the sources. As we've
seen, bandwidth is one such resource. The routers make the clients share
bandwidth, but not deterministically or statically. Instead, the clients
share the bandwidth in a probabilistic way.

Packet switching is not without its downsides:

1. **Packet loss**. The total amount of resources demanded by the packets
   can exceed the amount available. Once a router runs out of resources
   (e.g., memory for its packet queue), it cannot accept any further
   packets. If a packet arrives at just the wrong time, it's lost.

2. **Packet delay**. Packets move one hop at a time. And before a node
   forwards a packet, it must receive the packet in its entirety. This
   means that there's no guarantee that a packet will reach its destination
   by a certain time, particularly when there's a significant amount of
   traffic.
3. **More protocols.** From downsides (1) and (2), packet switching
   requires more protocols to ensure reliability and congestion control.
   Designing and implementing those protocols takes human time and monetary
   resources.

Despite these downsides, packet switching is for the most part
advantageous. In effect, packet switching networks are analogous to the
airline industry's ticketing practice.

As any frequent flier knows, airlines sell more tickets than there are
available seats. I.e., if there are 150 seats on the flight, the airline
might sell a 165 tickets. The airlines essentially gamble on the fact that
some customers won't show up or cancel.

Of course, there are situations where all 165 customers show up. In those
circumstances, the airlines are quick to offer vouchers and free
rebookings. From an economic perspective, the amount of value lost from
these vouchers and free rebookings is smaller compared to the amount lost
from unsold seats. And in the long run, the airlines keep their costs low.

The same idea applies in packet switching. There are situations where the
downsides mentioned above occur, but in the long run, packet switching
proves beneficial. To illustrate, suppose we had the following
circuit-switched network:

<Graph
	data={[
		{ link: [{ id: "router", r: 10, radial: 25, focus: "red" }, "a"] },
		{ link: ["c", "router"] },
		{ link: ["b", "router"] },
		{ link: ["d", "router"] },
		{ link: ["e", "router"] },
		{ link: ["f", "router"] },
		{ link: ["g", "router"] },
		{ link: ["h", "router"] },
		{ link: ["i", "router"] },
		{ link: ["j", "router"] },
		{
			link: ["router", { id: "server", r: 15, radial: 30, focus: "blue" }],
			focus: "hl",
		},
	]}
	height={300}
	width={400}
	containerWidth={70}
	collisionRadius={30}
	edgeLength={70}
/>

The network above consists of ten users (marked `a` through `j`),
connecting to a server that then connects to a router. Suppose the link
from the server to the router has a bandwidth of 1Mbps.

As we know, users aren't always active on a network. They might just be
active for, say, 10% of the time. With circuit switching, we can support 10
users. Each link has a 1Mbps (1000kbps) bandwidth, and if each user wants
100kbps, we have:

$$
	\dfrac{1000~\text{kbps}}{100~\text{kbps}} = 10
$$

The problem is, if the users are only active 10% of the time, we're wasting
bandwidth.

Now suppose that, instead of 10 users, there are 35 users, and the network
above is packet-switched. Given that each user is only active 10% of the
time, the probability of the link being in use is 10%.

What's the probability that more than 10 users are active? Well, we can
calculate it with a bit discrete probability:

$$
	\binom{35}{10} \times P^{10} + 1 - P^{35 - 10} = 0.0004
$$

That's a tiny, tiny chance.[^probability_note]

[^probability_note]:
    This calculation assumes that the 10% active time is uniformly
    distributed, and that the users are independent users.

From this discussion, we can see that packet switching is ideal for
"individual requests" — requests like quickly checking CNN or visiting some
other website. It's not ideal for "unified requests" — millions of users
suddenly requesting for some website illegally broadcasting the Superbowl.
