import { Sequence } from "@illus/Sequence";

<Metadata
	title={"Sorted Insertion"}
	description={"How to insert a new array element and maintain sort."}
	keywords={
		"static arrays, sorting, arrays, sequences, data structures and algorithms."
	}
/>

# Sorted Insertion

Suppose we had the following _sorted_ array:

<Sequence data={[4, 8, 13, 16, 20, 25, 28, 33, "", ""]} />

When inserting into a sorted array like the one above, we often want to
keep the array's sorted property. In other words, we want to insert the
element in a sorted position. In this case, `insert(18)` should place the
element ${18}$ after ${A_{3} = 16.}$ This requires placing ${18}$ at
${i = 4,}$ which is presently occupied by ${A_{4} = 20.}$ Accordingly, we
must make space for the new element. This is done by shifting the element
at 7, then 6, then 5, then 4.

How might this shifting be implemented? Well, let's consider a simpler
case. If we instead wrote `insert(34)`, then no shifting would occur, since
34 would be the largest element. If, however, we wrote `insert(32)`, then
33 would have to be shifted, since ${32 > 33.}$ Accordingly, when we shift
elements, we keep right-shifting, starting from the last element, until we
reach the _first_ element less than the argument passed to `insert()`
(i.e., the element we want to insert).[^inertnote] This implies that we
never have to check the elements less than the new element. For example,
with `insert(18)`, we never have to check the elements 4, 8, 13, and 16.
All that matters is 20, 25, 28, and 33. The implementation:

[^inertnote]:
    This algorithm only works because the array's elements are sorted.

```rust
insert(x):
	i = length-1;
	while (A[i] > x):
		array[i+1] = array[i]
		i--;
	A[i+1] = x;
```

The implementation above follows our reasoning. First, in line 2, we
establish our starting point: The last index in the array. Once that's
done, we enter the while-loop. If the new element, ${x,}$ is greater than
the current element, then perform the following: (1) Shift the current
element to the right; (2) Decrement the index (so we can then check the
element just before the start). As long as the new element ${x}$ is greater
than the current element, we keep performing the operation above. Once
we've arrived at an element greater less than ${x,}$ we exit the while loop
and proceed to line 6: Assign to the position after the current position
(an empty position) the new element ${x.}$

Looking at the annotations, we see that the time function for this
algorithm is roughly ${f(n) = n + 2.}$ Accordingly, this algorithm has a
time complexity of ${O(n)}$—linear time. In the best case scenario, ${x}$
would be greater than or equal to the last element, in which case we have a
time complexity of ${\Omega(1)}$—constant time.
