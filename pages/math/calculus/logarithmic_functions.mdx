import { Plot } from "@illus/Plot";
import { Tile } from "@components/Tile";

<Metadata
	title={"Logarithmic Functions"}
	description={"Notes on exponential functions"}
	keywords={
		"precalculus, mathematics, calculus, exponential functions, functions"
	}
/>

# Logarithmic Functions

1. [Graphs of Logarithmic Functions](#graphs-of-logarithmic-functions)
2. [Case Analysis: Logarithms](#case-analysis-logarithms)
3. [The Common Logarithm](#the-common-logarithm)
4. [The Binary Logarithm](#the-binary-logarithm)
5. [The Natural Logarithm](#the-natural-logarithm)
6. [Applications of Logarithms](#applications-of-logarithms)
7. [Logarithmic Multiplication](#logarithmic-multiplication)
8. [Logarithmic Division](#logarithmic-division)
9. [Graphs of Logarithmic Functions](#graphs-of-logarithmic-functions-1)
10. [Domain of a Logarithmic Function](#domain-of-a-logarithmic-function)
11. [Effect of the Base on the Graph](#effect-of-the-base-on-the-graph)
12. [Transformations of Logarithmic Functions](#transformations-of-logarithmic-functions)
    1. [Horizontal Translation](#horizontal-translation)
    2. [Vertical Translation](#vertical-translation)
    3. [Stretches and Compressions](#stretches-and-compressions)

The function ${f(x)=\log_{10}(x)}$ can be thought of as the zero-counting
function.

$$
\small
\begin{aligned}
	&10^0 = 1 \iff \log_{10}(1) = 0 \\
	&10^1 = 10 \iff \log_{10}(10) = 1 \\
	&10^2 = 100 \iff \log_{10}(100) = 2 \\
	&10^3 = 1,000 \iff \log_{10}(1,000) = 3 \\
	&10^4 = 10,000 \iff \log_{10}(10,000) = 4 \\
	&10^5 = 100,000 \iff \log_{10}(100,000) = 5 \\
	&10^6 = 1,000,000 \iff \log_{10}(1,000,000) = 6 \\
	&10^7 = 10,000,000 \iff \log_{10}(10,000,000) = 7 \\
	&10^8 = 100,000,000 \iff \log_{10}(100,000,000) = 8 \\
	&10^9 = 1,000,000,000 \iff \log_{10}(1,000,000,000) = 9 \\
	&10^{10} = 10,000,000,000 \iff \log_{10}(10,000,000,000) = 10
\end{aligned}
$$

Before we study the logarithmic function, we ought to be familiar with the
logarithm operator, ${\log.}$ Logarithms are simply another way of viewing
and thinking about exponents.

Consider this question: What is the 4th power of 2? We state this question
in formal mathematics as: Evaluate ${2^4.}$ The answer, of course, is 16:
${2^4 = 16.}$

Now consider this question: What power of 2 is 16? We state this question
formally as: Evaluate ${\log_{2}(16).}$ The answer here is:
${\log_{2}(16) = 4.}$ Informally:

1. Exponents: ${y = b^x \implies}$ What is the result if I multiply the
   number ${b}$ by itself ${x}$ times?

2. Logarithms: ${x = \log_{b}(y) \implies}$ How many times do I multiply
   ${b}$ by itself to get the number ${y?}$

Logarithms are simply a way of bringing exponents back to earth. With very
very large exponents, we get very very large numbers. Logarithms allow us
to look at those huge numbers in simpler terms. ${10^{100}}$ is a _googol_,
the digit 1 followed by 100 zeros, or ${1{\footnotesize\text{E}}100.}$
Instead of repeatedly writing such a huge number, we can simply think of
the number as 100, where ${\log_{10}(\text{googol}) = 100}$. Similarly,
both ${2^4 = 16}$ and ${\log_{2}(16) = 4}$ express the same relationship
between the numbers 2, 4, and 16. 2 is the base, 4 is the exponent, and 16
is the power. The only difference: Exponential form isolates the power, 16,
while logarithmic form isolates the exponent, 4.

$$
	\begin{aligned}
		\log_{2}(8) = 3 \iff 2^3 = 8
		\log_{3}(81) = 4 \iff 3^4 = 81
		\log_{5}(25) = 2 \iff 5^2 = 25
	\end{aligned}
$$

We can formalize the definition of a logarithm as the following:

> _Definition_. Where ${x > 0,}$ ${b > 0,}$ and ${b \neq 1,}$
>
> $$
> 	y = \log_{b}(x) \iff b^y = x
> $$

The variable ${b}$ is the _base_; ${c}$ is the _exponent_; and ${x}$ is the
_argument_.

## Graphs of Logarithmic Functions

The logarithmic function effectively &#8220;switches&#8221; the ${x}$ and
$
{y}$ values in an exponential function. Accordingly, the domain and range
of the exponential function are interchanged. Thus:

> _Definition_ . Given ${f(x) = \log_{b}(x),}$

$$
	\text{dom}(f) = (0, \infty) \\
	\text{ran}(f) = (- \infty , \infty)
$$

## Case Analysis: Logarithms

There are four cases for analyzing logarithms. Where ${b}$ is the _base_,

1. ${b \in \R^{-}}$
2. ${b = 0}$
3. ${b = 1}$
4. ${b \in \R^{+} : b \neq 1}$

Of the three cases above, the logarithm is defined only for the last case,
${b \in \R^{+} : b \neq 1.}$ To see why, we consider the other three cases.
If ${b \in \R^{-},}$ then we arrive at some difficulty. Remember,
logarithmic functions are an inverse of the exponential functions. Suppose
the following:

$$
	\log_{-2}(x) = 1/2
$$

This would be equivalent to:

$$
	(-2)^{1/2} = \sqrt{-2} = x
$$

Because the natural domain of the functions we are dealing with is ${\R,}$
the logarithmic function is _undefined_ where ${b \in \R^{-}.}$ Now
consider where ${b = 0.}$ If ${b = 0,}$ then we again run into difficulty:

$$
	\begin{aligned}
		\log_{0}(x) = 10 = 0^x = 5 \\
		\log_{0}(x) = 100 = 0^x = 10 \\
		\log_{0}(x) = 1000 = 0^x = 1000
	\end{aligned}
$$

The problem is that 0 raised to any ${n^{\text{\scriptsize{th}}}}$ power
is 0. Once again, the logarithmic function is undefined, this time for
${b = 0.}$ Finally, consider where ${b = 1.}$ Following the same approach:

$$
	\begin{aligned}
		\log_{1}(x) = 10 = 1^x = 10 \\
		\log_{1}(x) = 100 = 1^x = 10 \\
		\log_{1}(x) = 1000 = 1^x = 1000
	\end{aligned}
$$

Like 0, 1 raised to any ${n^{\text{\scriptsize{th}}}}$ power is 1. The
logarithmic function is undefined for ${b = 1.}$ For the reasons above, we
can never take the logarithm of a negative number, 0, or 1. The _value_, of
a logarithm can be negative, 1, or 0, but its _base_, cannot.

## The Common Logarithm

In mathematics, the base-10 logarithm is so common that is often written
without its base, 10. This logarithm is called common logarithm.

> _Definition_. In mathematics, the _common logarithm_ is defined as:
>
> $$
> 	y = \log(x) = \log_{10}(x) \equiv 10^y = x
> $$

## The Binary Logarithm

In a similar vein, the base-2 logaritm is so pervasive in computer science
and logic that it is often written without its base. This logarithm is
called the binary logarithm.

> _Definition_. In computer science, the _binary logarithm_ is defined as:
>
> $$
> 	y = \log(x) = \log_{2}(x) \equiv 2^y = x
> $$

How do we differentiate between the common logarithm and the binary
logarithm? Context. In computer science, it is almost always assumed that
${\log (x)}$ is the binary logarithm, ${\log_{2}(x).}$ In pure mathematics,
${\log (x)}$ is almost always assumed to be the common logarithm,
${\log_{10}(x).}$

## The Natural Logarithm

By far, the most frequently used base for logarithms is Euler's constant,
${e.}$ Base-${e}$ logarithms are so important in calculus and scientific
fields that they are specially named natural logarithms, and are provided
special notation, ${\ln(x).}$ The symbol ${ln}$ is derived from the Latin
_logarithmus naturali_.

> _Definition_. The _natural logarithm_ is a logarithm of base ${e.}$
>
> $$
> 	y = \log_{e}(x) = \ln(x) \equiv e^y = x
> $$

## Applications of Logarithms

Another way of understanding the relationship between logarithms and
exponentials is to revisit the exponential growth function. Exponents, as a
matter of applied mathematics, return the amount of _growth_ after time
${x}$ &mdash; the function ${g(x) = e^x.}$ On the other side, logarithms
return the amount of _time_ it takes for something to grow to ${x}$ &mdash;
the function ${t(x) = \ln(x).}$ Thus, ${f(x) = e^x}$ allows us to input a
value of _time_ and obtain the _growth_. ${f(x) = \ln(x)}$ allows us to
input a value of _growth_ and obtain the _time it would take to grow_.

If we think of logarithms in this manner, then the preceding discussion on
the bounds of logarithmic functions is much more intuitive. ${ln(1) = 0}$
is nonsensical; it does not take any time to grow from 1 to 1, because we
already are at 1.

What about ${ln(-1)?}$ This too is nonsensical in the context of discrete
real-world objects. If we think of ${g(x) = e^x}$ as measuring the growth
of, say, a deer population, it would not make sense to have a population of
-1. Accordingly, ${ln(-1) \implies \text{undefined}.}$ In other words,
there is no amount of time we can wait to get a negative deer population
(again, in the context of real-world objects; there is a solution involving
imaginary exponentials, but we are restricting our functions to the natural
domain of \R).

If we pass a float (a fractional value) into the logarithmic function, then
we are asking, How long does it take to grow to this fraction of the
current amount? Suppose we grow continuously at 100%, then asking for, say,
the time it would take to grow to 1/2 of the current amount requires
reversing the time (taking the negative time):

$$
	\ln(1/2) = -\ln(2) = -0.693
$$

The negative value ${-0.693}$ communicates, Go back 0.693 seconds, and you
will find half of the current amount. In general, flipping the fraction and
taking the negative gives us the value of float inputs into the logarithm:

$$
	\ln(1/3) = -\ln(3) = -1.09
$$

## Logarithmic Multiplication

Suppose the current amount is 1. How long would it take to grow to 9 times
the current amount? We can break this problem into smaller pieces. The
current amount takes an ${n}$ amount of time to grow 3 times, then another
${m}$ amount of time to grow 3 times.

$$
	\ln(9) = \ln(3) + \ln(3)
$$

In general, we have the following rule:

> _Definition._ Given the logarithm ${\ln(ab)}$,
>
> $$
> 	\ln(ab) = \ln(a \cdot b) = \ln(a) + \ln(b)
> $$

## Logarithmic Division

When we write ${\ln(3/4)}$ we are effectively asking, How long does it take
to grow 3 times the current amount and then take 1/4 of that? The answer:
The time it takes to grow 3 times the current amount is ${\ln(3).}$ The
time it takes to grow 1/4 of the current amount is ${-\ln(4).}$
Accordingly, ${\ln(3/4) = \ln(3) - \ln(4).}$ Thus, we have the following
rule:

> $$
> 	\ln(a/b) = \ln(a) - \ln(b)
> $$

## Graphs of Logarithmic Functions

The logarithmic function is the inverse of the exponential function. Thus,
we can think of every output of the logarithmic function as the input of an
exponential function. Because of this point, we have the following
characteristics of logarithmic functions:

> _Properties_. Given ${t(x) = \log_{b}(x),}$
>
> - ${\text{dom}(t) = (0, \infty) = \R_{\geq 0}}$
> - ${\text{ran}(t) = (-\infty, \infty) = \R}$

A table comparing the values can aid in understanding why the graphs appear
as they do:

| ${x}$ | ${y = 2^x}$ | ${x = \log_{2}(y)}$ |
| ----- | ----------- | ------------------- |
| -3    | 1/8         | -3                  |
| -2    | 1/4         | -2                  |
| -1    | 1/2         | -1                  |
| 0     | 1           | 0                   |
| 1     | 2           | 1                   |
| 2     | 4           | 2                   |
| 3     | 8           | 3                   |

| ${g(x) = 2^x}$ | ${t(x) = \log_{2}(x)}$ |
| -------------- | ---------------------- |
| (-3, 0.125)    | (0.125, -3)            |
| (-2, 0.25)     | (0.25, -2)             |
| (-1, 0.5)      | (0.5, -1)              |
| (0, 1)         | (1, 0)                 |
| (1, 2)         | (2, 1)                 |
| (2, 4)         | (4, 2)                 |
| (3, 8)         | (8, 3)                 |

Notice that the domain and range of the logarithmic function are the domain
and range of the exponential function, but switched. Recall: Given
${g(x) = b^x,}$ where ${b > 0, b \neq 1,}$
${\text{dom}(g) = (-\infty, \infty) = \R.}$ And
${\text{ran}(g) = (0, \infty) = \R_{\geq 0}.}$

This switch is apparent when we compare the graphs of ${g(x) = 2^x}$ and
${t(x) = \log_{2}(x):}$

<Plot
	functions={[
		{ f: (x) => 2 ** x, color: "var(--red)" },
		{ f: (x) => Math.log2(x), color: "var(--blue)" },
	]}
	geo={[
		{ type: "label", id: "g(x) = 2^x", xy: [4, 8], fill: "var(--red)" },
		{
			type: "label",
			id: "t(x) = \\log_2(x)",
			xy: [4, -2],
			fill: "var(--blue)",
		},
	]}
	id={"compare_exp_and_log"}
	scale={70}
/>

Notice that ${G(t)}$ &mdash; the graph of the logarithmic function &mdash;
has a vertical asymptote at ${x = 0.}$ This is because ${\text{dom}(t)}$
excludes 0. We must always remember this point when handling logarithmic
functions. Notice further that there are two _base cases_: (1) If
${x = 1,}$ then ${t(x) = 0.}$ (2) If ${x = b,}$ then ${t(x) = 1.}$ These
base cases correspond to two key points on the graph of a logarithmic
function:

- ${(1, 0)}$
- ${(b, 1)}$

## Domain of a Logarithmic Function

To properly analyze a logarithmic function's behavior, we must be aware of
our analysis's boundaries. The most obvious and critical boundaries lie in
the domain. For example, suppose ${t(x) = \log_{4}(2x - 3).}$

$$
\begin{aligned}
		\text{dom}(t) &= \{ x \in \R \mid 2x - 3 > 0 \} \\
		&= \{ x \in \R \mid 2x > 3 \}  \\
		&= \{ x \in \R \mid x > 3/2 \} \\
		&= \{ x \in \R \mid x > 1.5 \} \\
		&\equiv (1.5, \infty)
\end{aligned}
$$

From the example above, we have the following algorithm:

1. Given a function of the form ${t(x) = \log_{b}(x),}$ to
   ${\text{dom}(t),}$
2. Establish the inequality showing the argument ${x}$ is greater than 0.
3. Solve for ${x.}$

With the domain established, we can graph the parent function,
${t(x) =
\log_{b}(x).}$ To do so, the following algorithm is helpful:

1. Given a logarithmic function of the form ${f(x) = \log_{b}(x),}$
2. Draw and label the vertical asymptote, ${x = 0.}$
3. Plot the 𝑥-intercept ${(0,1).}$
4. Plot the key point, ${(b, 1).}$
5. Draw a smooth curve through the points.

## Effect of the Base on the Graph

The base of a logarithmic function affects how high it &#8220;archs.&#8221;
As the value of the base increases, the more the logarithmic function's
graph compresses.

More specifically, there are two cases for when the base affects the
logarithmic function's graph, (i) ${b}$ is greater than 1, and (ii) ${b}$
is between 0 and 1:

1. ${1 < b}$
2. ${0 < b < 1}$

To see the difference between the two cases, compare the graphs of
${f(x) = \log_{2}(x)}$ and ${q(x) = \log_{1/2}(x):}$

Suppose ${f(x) = \log_{b}x.}$ From the comparison above, we have the
following observations:

1. ${f}$ is an injective function (one-to-one).
2. ${f}$ has a vertical asymptote at ${x = 0.}$
3. ${\text{dom}(f) = \R = (-\infty, \infty)}$
4. ${f}$ has an 𝑥-intercept at ${(0,1)}$
5. ${f}$ has the base cases ${(1,0)}$ and ${(b,1)}$
6. ${f}$ has no 𝑦-intercept.
7. ${f}$ is increasing iff ${b > 1}$
8. ${f}$ is decreasing iff ${0 < b < 1}$

## Transformations of Logarithmic Functions

Like many other graphs, we can transform the graph of a logarithmic
function by translating, stretching, compressing, and reflecting the parent
function ${t(x) = \log_{b}(x).}$

### Horizontal Translation

The logarithmic function's graph translates horizontally when a constant
${C}$ is added to the _input_ of the parent function
${t(x) = \log_{b}(x).}$ Thus:

- ${a(x) = \log_{b}(x + C)}$ shifts ${G(t)}$ to the _left_.
- ${b(x) = \log_{b}(x - C)}$ shifts ${G(t)}$ to the _right_.

A visual comparison:

Summarizing these properties:

> _Properties_. Let ${t(x) = \log_{b}(x).}$ Then, the transformation
> ${s(x) = \log_{b}(x + c):}$

- If ${c > 0,}$ i.e., ${c \in \R^{+}:}$
  - ${G(t)}$ is shifted to the left ${c}$ units
  - ${G(s)}$ has the asymptote ${x = -c}$
  - ${\text{dom}(s) = (-c, \infty)}$
  - ${\text{ran}(s) = \R = (-\infty, \infty)}$
- If ${c < 0,}$ i.e., ${c \in \R^{-}:}$
  - ${G(t)}$ is shifted to the right ${c}$ units.
  - ${G(s)}$ has the asymptote ${x = c}$
  - ${\text{dom}(s) = (c, \infty)}$
  - ${\text{ran}(s) = \R = (-\infty, \infty)}$

From the properties above, we have the following algorithm: Given a
logarithmic function of the form ${f(x) = \log_{b}(x + c),}$ to plot
${G(f),}$

1. Identify the horizontal shift.
2. If ${c > 0,}$ graph of ${t(x) = \log_{b}(x)}$ shifts _left._
3. If ${c < 0,}$ graph of ${t(x) = \log_{b}(x)}$ shifts _right._
4. Plot vertical asymptote ${x = -c.}$
5. Identify base cases, plot key points.

### Vertical Translation

When a constant ${d}$ is added to the _outputs_ of ${t(x) = \log_{b}(x)}$,
i.e., ${a(x) = \log_{b}(x) + d,}$ then the parent function vertically
translates. If ${d > 0,}$ ${G(t)}$ shifts _up_. If ${d < 0,}$ ${G(t)}$
shifts _down_.

Transforming ${t(x) = \log_{b}(x)}$ to ${g(x) = \log_{b}(x) + d}$

Transforming ${t(x) = \log_{b}(x)}$ to ${h(x) = \log_{b}(x) - d}$

From the comparisons above, we have the following properties:

> _Properties_. Given the parent function ${t(x) = \log_{b}(x),}$ and a
> constant ${d}$ where ${d \in \R : d \neq 0,}$

- ${f(x) = \log_{b}(x) + d}$
  - shifts the parent function ${d}$ units up
  - has the vertical asymptote ${x = 0}$
  - ${\text{dom}(f) = (0, \infty) = \R_{\geq 0}}$
  - ${\text{ran}(f) = (-\infty, \infty) = \R}$
- ${h(x) = \log_{b}(x) - d}$
  - shifts the parent function ${d}$ units down
  - has the vertical asymptote ${x = 0}$
  - ${\text{dom}(f) = (0, \infty) = \R_{\geq 0}}$
  - ${\text{ran}(f) = (-\infty, \infty) = \R}$

Following these properties, we have a helpful algorithm for plotting a
vertical shift: Given a logarithmic function of the form
${f(x) = \log_{b}(x) + d,}$

1. Identify the vertical shift:
2. If ${d > 0,}$ shift the parent function up.
3. If ${d < 0,}$ shift the parent function down.
4. Plot the vertical asymptote ${x = 0.}$
5. Identify the base cases (key points) from the parent function.
6. Find the base cases' new coordinates for the shifted functions by adding
   ${d}$ to the ${y}$ coordinate.
7. Plot a smooth curve through these base cases.

### Stretches and Compressions

When the parent function ${t(x) = \log_{b}(x)}$ is multiplied by a constant
${a}$ where ${a > 1,}$ we _stretch_ the parent function.

When the parent function ${t(x) = \log_{b}(x)}$ is multiplied by a constant
${a}$ where ${0 < a < 1,}$ we _compress_ the parent function. For example,
when we multiply ${t(x) = \log_{b}(x)}$ by the constant ${a,}$ where
${a > 1,}$ we stretch the parent function's graph. And when we multiply
${t(x) = \log_{b}(x)}$ by the constant ${1/a,}$ where ${a > 1,}$ we
compress the parent function's graph. A comparison is helpful here:
