import { Plot } from "@illus/Plot";

<Metadata
	title={"Exponential Functions"}
	description={"Notes on exponential functions"}
	keywords={
		"precalculus, mathematics, calculus, exponential functions, functions"
	}
/>

# Logarithmic Functions

The function ${f(x)=\log_{10}(x)}$ can be thought of as the
zero-counting function.

$$
\begin{aligned}
	&10^0 = 1 \iff \log_{10}(1) = 0
	&10^1 = 10 \iff \log_{10}(10) = 1
	&10^2 = 100 \iff \log_{10}(100) = 2
	&10^3 = 1,000 \iff \log_{10}(1,000) = 3
	&10^4 = 10,000 \iff \log_{10}(10,000) = 4
	&10^5 = 100,000 \iff \log_{10}(100,000) = 5
	&10^6 = 1,000,000 \iff \log_{10}(1,000,000) = 6
	&10^7 = 10,000,000 \iff \log_{10}(10,000,000) = 7
	&10^8 = 100,000,000 \iff \log_{10}(100,000,000) = 8
	&10^9 = 1,000,000,000 \iff \log_{10}(1,000,000,000) = 9
	&10^{10} = 10,000,000,000 \iff \log_{10}(10,000,000,000) = 10
\end{aligned}
$$


Before we study the logarithmic function, we ought to be familiar with the logarithm operator, ${\log.}$ Logarithms are simply another way of viewing and thinking about exponents.

Consider this question: What is the 4th power of 2? We state this question in formal mathematics as: Evaluate ${2^4.}$ The answer, of course, is 16: ${2^4 = 16.}$

Now consider this question: What power of 2 is 16? We state this question formally as: Evaluate ${\log_{2}(16).}$ The answer here is: ${\log_{2}(16) = 4.}$ Informally:

1. Exponents: ${y = b^x \implies}$ What is the result if I multiply the number ${b}$ by itself ${x}$ times?

2. Logarithms: ${x = \log_{b}(y) \implies}$ How many times do I multiply ${b}$ by itself to get the number ${y?}$

Logarithms are simply a way of bringing exponents back to earth. With very very large exponents, we get very very large numbers. Logarithms allow us to look at those huge numbers in simpler terms. ${10^{100}}$ is a _googol_, the digit 1 followed by 100 zeros, or ${1{\footnotesize\text{E}}100.}$ Instead of repeatedly writing such a huge number, we can simply think of the number as 100, where ${\log_{10}(\text{googol}) = 100}$. Similarly, both ${2^4 = 16}$ and ${\log_{2}(16) = 4}$ express the same relationship between the numbers 2, 4, and 16. 2 is the base, 4 is the exponent, and 16 is the power. The only difference: Exponential form isolates the power, 16, while logarithmic form isolates the exponent, 4.

$$
	\begin{aligned}
		\log_{2}(8) = 3 \iff 2^3 = 8
		\log_{3}(81) = 4 \iff 3^4 = 81
		\log_{5}(25) = 2 \iff 5^2 = 25
	\end{aligned}
$$

We can formalize the definition of a logarithm as the following:

> _Definition_.  Where ${x > 0,}$ ${b > 0,}$ and ${b \neq 1,}$
> $$
>	y = \log_{b}(x) \iff b^y = x
> $$

The variable ${b}$ is the _base_; ${c}$ is the _exponent_; and ${x}$ is the _argument_.

## Graphs of Logarithmic Functions
The logarithmic function effectively &#8220;switches&#8221; the ${x}$ and $ {y}$ values in an exponential function. Accordingly, the domain and range of the exponential function are interchanged. Thus:

> _Definition_ . Given ${f(x) = \log_{b}(x),}$
$$
	\text{dom}(f) = (0, \infty) \\
	\text{ran}(f) = (- \infty , \infty)
$$

## Case Analysis: Logarithms
There are four cases for analyzing logarithms. Where ${b}$ is the _base_,

1. ${b \in \R^{-}}$
2. ${b = 0}$
3. ${b = 1}$
4. ${b \in \R^{+} : b \neq 1}$

Of the three cases above, the logarithm is defined only for the last case, ${b \in \R^{+} : b \neq 1.}$ To see why, we consider the other three cases.  If ${b \in \R^{-},}$ then we arrive at some difficulty. Remember, logarithmic functions are an inverse of the exponential functions. Suppose the following:

$$
	\log_{-2}(x) = 1/2
$$

This would be equivalent to:

$$
	(-2)^{1/2} = \sqrt{-2} = x
$$

Because the natural domain of the functions we are dealing with is ${\R,}$ the logarithmic function is _undefined_ where ${b \in \R^{-}.}$ Now consider where ${b = 0.}$ If ${b = 0,}$ then we again run into difficulty:

$$
	\begin{aligned}
		\log_{0}(x) = 10 = 0^x = 5 \\
		\log_{0}(x) = 100 = 0^x = 10 \\
		\log_{0}(x) = 1000 = 0^x = 1000
	\end{aligned}
$$

The problem is that 0 raised to any ${n^{\text{\scriptsize{th}}}}$ power is 0. Once again, the logarithmic function is undefined, this time for ${b = 0.}$ Finally, consider where ${b = 1.}$ Following the same approach:

$$
	\begin{aligned}
		\log_{1}(x) = 10 = 1^x = 10 \\
		\log_{1}(x) = 100 = 1^x = 10 \\
		\log_{1}(x) = 1000 = 1^x = 1000
	\end{aligned}
$$

Like 0, 1 raised to any ${n^{\text{\scriptsize{th}}}}$ power is 1. The logarithmic function is undefined for ${b = 1.}$ For the reasons above, we can never take the logarithm of a negative number, 0, or 1. The _value_, of a logarithm can be negative, 1, or 0, but its _base_, cannot.

## The Common Logarithm
In mathematics, the base-10 logarithm is so common that is often written without its base, 10. This logarithm is called <span class="term">common logarithm</span>.

> _Definition_.  In mathematics, the _common logarithm_ is defined as:
>$$
>	y = \log(x) = \log_{10}(x) \equiv 10^y = x
>$$

## The Binary Logarithm
In a similar vein, the base-2 logaritm is so pervasive in computer science and logic that it is often written without its base. This logarithm is called the <span class="term">binary logarithm</span>.


> _Definition_.  In computer science, the _binary logarithm_ is defined as:
>$$
>	y = \log(x) = \log_{2}(x) \equiv 2^y = x
>$$


How do we differentiate between the common logarithm and the binary logarithm? Context. In computer science, it is almost always assumed that ${\log (x)}$ is the binary logarithm, ${\log_{2}(x).}$ In pure mathematics, ${\log (x)}$ is almost always assumed to be the common logarithm, ${\log_{10}(x).}$

## The Natural Logarithm
By far, the most frequently used base for logarithms is Euler's constant, ${e.}$ Base-${e}$ logarithms are so important in calculus and scientific fields that they are specially named <span class="term">natural logarithms</span>, and are provided special notation, ${\ln(x).}$ The symbol ${ln}$ is derived from the Latin _logarithmus naturali_.

> _Definition_.  The _natural logarithm_ is a logarithm of base ${e.}$
>$$
>	y = \log_{e}(x) = \ln(x) \equiv e^y = x
>$$

## Applications of Logarithms
Another way of understanding the relationship between logarithms and exponentials is to revisit the exponential growth function. Exponents, as a matter of applied mathematics, return the amount of _growth_ after time ${x}$ &mdash; the function ${g(x) = e^x.}$ On the other side, logarithms return the amount of _time_ it takes for something to grow to ${x}$ &mdash; the function ${t(x) = \ln(x).}$ Thus, ${f(x) = e^x}$ allows us to input a value of _time_ and obtain the _growth_. ${f(x) = \ln(x)}$ allows us to input a value of _growth_ and obtain the _time it would take to grow_.

If we think of logarithms in this manner, then the preceding discussion on the bounds of logarithmic functions is much more intuitive. ${ln(1) = 0}$ is nonsensical; it does not take any time to grow from 1 to 1, because we already are at 1.

What about ${ln(-1)?}$ This too is nonsensical in the context of discrete real-world objects. If we think of ${g(x) = e^x}$ as measuring the growth of, say, a deer population, it would not make sense to have a population of -1. Accordingly, ${ln(-1) \implies \text{undefined}.}$ In other words, there is no amount of time we can wait to get a negative deer population (again, in the context of real-world objects; there is a solution involving imaginary exponentials, but we are restricting our functions to the natural domain of \R).

If we pass a float (a fractional value) into the logarithmic function, then we are asking, How long does it take to grow to this fraction of the current amount? Suppose we grow continuously at 100%, then asking for, say, the time it would take to grow to 1/2 of the current amount requires reversing the time (taking the negative time):

$$
	\ln(1/2) = -\ln(2) = -0.693
$$

The negative value ${-0.693}$ communicates, Go back 0.693 seconds, and you will find half of the current amount. In general, flipping the fraction and taking the negative gives us the value of float inputs into the logarithm:

$$
	\ln(1/3) = -\ln(3) = -1.09
$$

## Logarithmic Multiplication
Suppose the current amount is 1. How long would it take to grow to 9 times the current amount?  We can break this problem into smaller pieces. The current amount takes an ${n}$ amount of time to grow 3 times, then another ${m}$ amount of time to grow 3 times.

$$
	\ln(9) = \ln(3) + \ln(3)
$$

In general, we have the following rule:

> _Definition._ Given the logarithm ${\ln(ab)}$,
>$$
>	\ln(ab) = \ln(a \cdot b) = \ln(a) + \ln(b)
>$$


## Logarithmic Division
When we write ${\ln(3/4)}$ we are effectively asking, How long does it take to grow 3 times the current amount and then take 1/4 of that? The answer: The time it takes to grow 3 times the current amount is ${\ln(3).}$ The time it takes to grow 1/4 of the current amount is ${-\ln(4).}$ Accordingly, ${\ln(3/4) = \ln(3) - \ln(4).}$ Thus, we have the following rule:

>$$
>	\ln(a/b) = \ln(a) - \ln(b)
>$$

## Graphs of Logarithmic Functions
The logarithmic function is the inverse of the exponential function. Thus, we can think of every output of the logarithmic function as the input of an exponential function. Because of this point, we have the following characteristics of logarithmic functions:

> _Properties_.  Given ${t(x) = \log_{b}(x),}$
>- ${\text{dom}(t) = (0, \infty) = \R_{\geq 0}}$
>- ${\text{ran}(t) = (-\infty, \infty) = \R}$

A table comparing the values can aid in understanding why the graphs appear as they do:

<figure>
<figure class="table">
<table class="truth_table">
<thead>
	<th>${x}$</th>
	<th>${y = 2^x}$</th>
	<th>${x = \log_{2}(y)}$</th>
</thead>
<tbody>
	<tr>
		<td>-3</td>
		<td>1/8</td>
		<td>-3</td>
	</tr>
	<tr>
		<td>-2</td>
		<td>1/4</td>
		<td>-2</td>
	</tr>
	<tr>
		<td>-1</td>
		<td>1/2</td>
		<td>-1</td>
	</tr>
	<tr>
		<td>0</td>
		<td>1</td>
		<td>0</td>
	</tr>
	<tr>
		<td>1</td>
		<td>2</td>
		<td>1</td>
	</tr>
	<tr>
		<td>2</td>
		<td>4</td>
		<td>2</td>
	</tr>
	<tr>
		<td>3</td>
		<td>8</td>
		<td>3</td>
	</tr>
</tbody>
</table>
</figure>
<figure class="table">
<table class="truth_table">
<thead>
	<th>${g(x) = 2^x}$</th>
	<th>${t(x) = \log_{2}(x)}$</th>
</thead>
<tbody>
	<tr>
		<td>(-3, 0.125)</td>
		<td>(0.125, -3)</td>
	</tr>
	<tr>
		<td>(-2, 0.25)</td>
		<td>(0.25, -2)</td>
	</tr>
	<tr>
		<td>(-1, 0.5)</td>
		<td>(0.5, -1)</td>
	</tr>
	<tr>
		<td>(0, 1)</td>
		<td>(1, 0)</td>
	</tr>
	<tr>
		<td>(1, 2)</td>
		<td>(2, 1)</td>
	</tr>
	<tr>
		<td>(2, 4)</td>
		<td>(4, 2)</td>
	</tr>
	<tr>
		<td>(3, 8)</td>
		<td>(8, 3)</td>
	</tr>
</tbody>
</table>
</figure>
</figure>

Notice that the domain and range of the logarithmic function are the domain
and range of the exponential function, but switched. Recall: Given ${g(x) =
b^x,}$ where ${b > 0, b \neq 1,}$ ${\text{dom}(g) = (-\infty, \infty) =
\R.}$ And ${\text{ran}(g) = (0, \infty) = \R_{\geq 0}.}$


This switch is apparent when comparing the graphs of ${g(x) = 2^x}$ and
${t(x) = \log_{2}(x):}$

<figure>
<img
src="{% static 'images/exponential_v_log.svg' %}"
alt="exponential v log"
loading="lazy"
/>
</figure>

Notice that ${G(t)}$ &mdash; the graph of the logarithmic function &mdash;
has a vertical asymptote at ${x = 0.}$ This is because ${\text{dom}(t)}$
excludes 0. We must always remember this point when handling logarithmic
functions. Notice further that there are two
_base cases_: (1) If ${x = 1,}$ then ${t(x) =
0.}$ (2) If ${x = b,}$ then ${t(x) = 1.}$ These base cases correspond to two
key points on the graph of a logarithmic function:

<figure>
<div>
${(1, 0)}$
${(b, 1)}$
</div>
</figure>

## Domain of a Logarithmic Function.
 To properly
analyze a logarithmic function's behavior, we must be aware of our
analysis's boundaries. The most obvious and critical boundaries lie in the
domain. For example, suppose ${t(x) = \log_{4}(2x - 3).}$

<figure>
<div>
${\text{dom}(t) = \{ x \in \R \mid 2x - 3 > 0 \}}$
${\phantom{\text{dom}(t)} = \{ x \in \R \mid 2x > 3 \} }$
${\phantom{\text{dom}(t)} = \{ x \in \R \mid x > 3/2 \} }$

${\phantom{\text{dom}(t)} = \{ x \in \R \mid x > 1.5 \} \equiv (1.5,
\infty)}$

</div>
</figure>
From the example above, we have the following algorithm:
<figure>
<div class="rule">

## Algorithm.
 Given a function of the form
${t(x) = \log_{b}(x),}$ to ${\text{dom}(t),}$

<ol>
<li>
	Establish the inequality showing the argument ${x}$ is greater than 0.
</li>
<li>Solve for ${x.}$</li>
</ol>
</div>
</figure>

With the domain established, we can graph the parent function, ${t(x) =
\log_{b}(x).}$ To do so, the following algorithm is helpful:

<figure>
<div class="rule">

## Algorithm.
 Given a logarithmic function of
the form ${f(x) = \log_{b}(x),}$

<ol>
<li>Draw and label the vertical asymptote, ${x = 0.}$</li>
<li>Plot the ${\text{$x$-intercept},}$ ${(0,1).}$</li>
<li>Plot the key point, ${(b, 1).}$</li>
<li>Draw a smooth curve through the points.</li>
</ol>
</div>
</figure>

## Effect of the Base on the Graph.
 The base of a
logarithmic function affects how high it &#8220;archs.&#8221; As the value
of the base increases, the more the logarithmic function's graph compresses.

<figure>
<img
src="{% static 'images/log_vertical_compress.svg' %}"
alt="vertical compression log"
loading="lazy"
/>
</figure>

More specifically, there are two cases for when the base affects the
logarithmic function's graph, (i) ${b}$ is greater than 1, and (ii) ${b}$ is
between 0 and 1:

<figure>
<ul>
<li>${1 < b}$</li>
<li>${0 < b < 1}$</li>
</ul>
</figure>

To see the difference between the two cases, compare the graphs of ${f(x) =
\log_{2}(x)}$ and ${q(x) = \log_{1/2}(x):}$


<figure>
<img src="{% static 'images/log_2.svg' %}" alt="log 2" loading="lazy" />
<figcaption>${\log_{2}(x)}$, ${b > 1}$</figcaption>
</figure>
<figure>
<img
src="{% static 'images/log_half.svg' %}"
alt="log half"
loading="lazy"
/>
<figcaption>${\log_{0.5}(x)}$, ${0 < b < 1}$</figcaption>
</figure>


Suppose ${f(x) = \log_{b}x.}$ From the comparison above, we have the
following observations:


<ul>
<li>${f}$ is an injective function (one-to-one).</li>
<li>${f}$ has a vertical asymptote at ${x = 0.}$</li>
<li>${\text{dom}(f) = \R = (-\infty, \infty)}$</li>
<li>${f}$ has an ${\text{$x$-intercept}}$ at ${(0,1)}$</li>

<li>${f}$ has the base cases ${(1,0)}$ and ${(b,1)}$</li>
<li>${f}$ has no ${\text{$y$-intercept}}$</li>
<li>${f}$ is increasing iff ${b > 1}$</li>
<li>${f}$ is decreasing iff ${0 < b < 1}$</li>
</ul>


<section id="transformations_of_logarithmic_graphs">
<h4>Transformations of Logarithmic Functions</h4>

Like many other graphs, we can transform the graph of a logarithmic function
by translating, stretching, compressing, and reflecting the parent function
${t(x) = \log_{b}(x).}$



## Horizontal Translation.
 The logarithmic
function's graph translates horizontally when a constant ${C}$ is added to
the _input_ of the parent function ${t(x) =
\log_{b}(x).}$ Thus:


<figure>
<ul>
<li>
${a(x) = \log_{b}(x + C)}$ shifts ${G(t)}$ to the
_left_.
</li>
<li>
${b(x) = \log_{b}(x - C)}$ shifts ${G(t)}$ to the
_right_.
</li>
</ul>
</figure>

A visual comparison:

<figure>
<img
src="{% static 'images/log_left_shift.svg' %}"
alt="log left"
loading="lazy"
/>
<ul>
<li>Asymptote changes to ${x = - c}$</li>
<li>${\text{dom}(a) = (-c, \infty)}$</li>
<li>${\text{ran}(a) = (-\infty, \infty)}$</li>
</ul>
</figure>
<figure>
<img
src="{% static 'images/log_shift_right.svg' %}"
alt="log right"
loading="lazy"
/>
<ul>
<li>Asymptote changes to ${x = c}$</li>
<li>${\text{dom}(b) = (c, \infty)}$</li>
<li>${\text{ran}(b) = (-\infty, \infty)}$</li>
</ul>
</figure>

Summarizing these properties:

<figure>
<div class="rule">

## Properties.
 Let ${t(x) = \log_{b}(x).}$ Then,
the transformation ${s(x) = \log_{b}(x + c):}$

<ul>
<li>If ${c > 0,}$ i.e., ${c \in \R^{+}:}$</li>
<ul>
	<li>${G(t)}$ is shifted to the left ${c}$ units</li>
	<li>${G(s)}$ has the asymptote ${x = -c}$</li>
	<li>${\text{dom}(s) = (-c, \infty)}$</li>
	<li>${\text{ran}(s) = \R = (-\infty, \infty)}$</li>
</ul>
</ul>
<ul>
<li>If ${c < 0,}$ i.e., ${c \in \R^{-}:}$</li>
<ul>
	<li>${G(t)}$ is shifted to the right ${c}$ units.</li>
	<li>${G(s)}$ has the asymptote ${x = c}$</li>
	<li>${\text{dom}(s) = (c, \infty)}$</li>
	<li>${\text{ran}(s) = \R = (-\infty, \infty)}$</li>
</ul>
</ul>
</div>
</figure>
From the properties above, we have the following algorithm:
<figure>
<div class="rule">

## Algorithm.
 Given a logarithmic function of
the form ${f(x) = \log_{b}(x + c),}$ to plot ${G(f):}$

<ol>
<li>Identify the horizontal shift.</li>
<ul>
	<li>
		If ${c > 0,}$ graph of ${t(x) = \log_{b}(x)}$ shifts
		_left._
	</li>
	<li>
		If ${c < 0,}$ graph of ${t(x) = \log_{b}(x)}$ shifts
		_right._
	</li>
</ul>
<li>Plot vertical asymptote ${x = -c.}$</li>
<li>Identify base cases, plot key points.</li>
</ol>
</div>
</figure>


## Vertical Translation.
 When a constant ${d}$ is
added to the _outputs_ of ${t(x) =
\log_{b}(x)}$, i.e., ${a(x) = \log_{b}(x) + d,}$ then the parent function
vertically translates. If ${d > 0,}$ ${G(t)}$ shifts
_up_. If ${d < 0,}$ ${G(t)}$ shifts
_down_.

Transforming ${t(x) = \log_{b}(x)}$ to ${g(x) = \log_{b}(x) + d}$
<figure>
<img
src="{% static 'images/log_shift_up.svg' %}"
alt="log up"
loading="lazy"
/>
</figure>
Transforming ${t(x) = \log_{b}(x)}$ to ${h(x) = \log_{b}(x) - d}$
<figure>
<img
src="{% static 'images/log_shift_down.svg' %}"
alt="log up"
loading="lazy"
/>
</figure>
From the comparisons above, we have the following properties:
<figure>
<div class="rule">

## Properties.
 Given the parent function ${t(x)
= \log_{b}(x),}$ and a constant ${d}$ where ${d \in \R : d \neq 0,}$

<ul>
<li>${f(x) = \log_{b}(x) + d}$</li>
<ul>
	<li>shifts the parent function ${d}$ units up</li>
	<li>has the vertical asymptote ${x = 0}$</li>
	<li>${\text{dom}(f) = (0, \infty) = \R_{\geq 0}}$</li>
	<li>${\text{ran}(f) = (-\infty, \infty) = \R}$</li>
</ul>
<li>${h(x) = \log_{b}(x) - d}$</li>
<ul>
	<li>shifts the parent function ${d}$ units down</li>
	<li>has the vertical asymptote ${x = 0}$</li>
	<li>${\text{dom}(f) = (0, \infty) = \R_{\geq 0}}$</li>
	<li>${\text{ran}(f) = (-\infty, \infty) = \R}$</li>
</ul>
</ul>
</div>
</figure>

Following these properties, we have a helpful algorithm for plotting a
vertical shift:

<figure>
<div class="rule">

## Algorithm.
 Given a logarithmic function of
the form ${f(x) = \log_{b}(x) + d,}$

<ol>
<li>Identify the vertical shift:</li>
<ul>
	<li>If ${d > 0,}$ shift the parent function up.</li>
	<li>If ${d < 0,}$ shift the parent function down.</li>
</ul>
<li>Plot the vertical asymptote ${x = 0.}$</li>
<li>
	Identify the base cases (key points) from the parent function. Find
	the base cases' new coordinates for the shifted functions by adding
	${d}$ to the ${y}$ coordinate.
</li>
<li>Plot a smooth curve through these base cases.</li>
</ol>
</div>
</figure>


## Stretches and Compressions.
 When the parent
function ${t(x) = \log_{b}(x)}$ is multiplied by a constant ${a}$ where ${a
> 1,}$ we _stretch_ the parent function.
## Compressions.
 When the parent function ${t(x) =
\log_{b}(x)}$ is multiplied by a constant ${a}$ where ${0 < a < 1,}$ we
_compress_ the parent function. For
example, when we multiply ${t(x) = \log_{b}(x)}$ by the constant ${a,}$
where ${a > 1,}$ we stretch the parent function's graph. And when we
multiply ${t(x) = \log_{b}(x)}$ by the constant ${1/a,}$ where ${a > 1,}$ we
compress the parent function's graph. A comparison is helpful here:

</section>
{% endblock %}
